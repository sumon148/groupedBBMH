---
title: "groupedBBMH: Beta-Binomial Model with Metropolis-Hastings for Group-Testing Data"
author: "Sumonkanti Das"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    fig_width: 8
    fig_height: 5
vignette: >
  %\VignetteIndexEntry{groupedBBMH: Beta-Binomial Model with Metropolis-Hastings for Group-Testing Data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---



```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


# Introduction

The **groupedBBMH** R package provides tools for fitting **nested beta-binomial hierarchical models** designed for **group-testing data in biosecurity surveillance**, explicitly accounting for imperfect testing conditions. In routine inspections of imported agricultural consignments, only group-level binary outcomes—positive or negative—are observed, without information on the exact number of contaminated items. This package extends traditional beta-binomial modeling by incorporating the **nested structure of the population** as well as **imperfect test sensitivity and specificity**, offering **exact inference** via a Metropolis-Hastings (MH) algorithm and **Maximum Likelihood Estimation**. For faster computation, an approximate **beta-binomial** model can be developed using standard R packages such as `brms` (Bayesian) or `VGAM` (MLE). The `groupedBBMH` package also allows users to specify a **biologically meaningful minimum prevalence threshold** $k$, ensuring that estimates respect the lower bound of plausible contamination levels. Overall, the package supports estimation of contamination prevalence, quantification of the risk of undetected contamination, and facilitates risk-based decision-making through model-based simulations that account for test accuracy and minimum prevalence thresholds.

`groupedBBMH` implements the methods developed in *Das et al. (2025)*, providing exact and approximate estimation for beta-binomial models with censored group-testing data while explicitly accounting for group-level test inaccuracy (sensitivity, $\Delta$ and specificity $\Lambda$) and biologically meaningful minimum prevalence threshold. While existing R packages such as `brms` or `VGAM` can fit approximate beta-binomial models in case of perfect test ($\Delta=\Lambda=1$ ) and zero threshold ($k=0$), `groupedBBMH` enables fitting the **exact model** according to the nested structure of the population, test inaccuracy and minimum prevalence threshold.

This vignette is organized as follows:

1. **Mathematical Background & Notation**  
   Definitions of $t_{yi}$, $b$, $m$, $T_{Xi}$, $L_i$, and the beta-binomial population models in exact and approximate form under test accuracy ($\Delta$ and $\Lambda$) and minimum positive prevalence $k$.  
2. **Case Study & Basic Usage of Package Functions**  
   Describing a case study and then demonstration of model fitting under different scenarios    and then calculation of leakage parameters.  
3. **Model-based simulation**  
   Assessing community-risk based on model-based simulation using the estimated BB model        parameters from the case study.  
4. **Session Info & References**  
   `sessionInfo()` output and full bibliographic entries.


# Installation

You can install the development version of `groupedHG` as below.

```r
install.packages("devtools")
devtools::install_github("sumon148/groupedBBMH")
```


```{r setup}
library(groupedBBMH)
library(ggplot2)
library(ggpubr)
library(MASS)
library(bayesplot)
```


# Mathematical Background

The `groupedBBMH` package provides tools for analyzing group (pooled) sampling data under both perfect and imperfect testing conditions. It supports inference on contamination prevalence, quantifies the risk of undetected contamination (leakage), and facilitates risk-based decision-making through model-based simulations. The package accounts for test imperfections and allows specifying a biologically meaningful minimum positive prevalence. Both exact and approximate beta-binomial distributions of the group-testing outcomes are implemented to calculate leakage probability and the expected number of contaminated items per batch.

To illustrate the underlying nested model, consider a biosecurity scenario involving the importation of frozen seafood into a country. Suppose there are $D$ consignments imported annually, each consisting of approximately $B$ groups, with each group containing $m$ items — so that the total number of items per batch is $N = mB$.

From each batch, a simple random sample of $b$ groups is selected for group testing in screening procedure. These tests, which screen for pathogens or contaminants, are typically imperfect. We assume a constant sensitivity $\Delta$ — the probability that a test correctly detects infection when it is present — and a constant specificity $\Lambda$ — the probability that a test correctly identifies no infection when it is absent.

For each batch, the only observed outcome is the number of positive groups ($t_{yi}$) among the $b$ tested groups. The below notations are used to develop the nested beta-binomial models.


## Notation

- $N$: Number of units (e.g., prawns) in a consignment  
- $B$: Number of groups (pools) in a consignment  
- $m$: Group (pool) size, $m = N/B$  
- $b$: Number of groups selected for testing  
- $X_{ij\ell}$: Indicator for contamination of unit $\ell$ in group $j$ of consignment $i$  
- $X_{ij}$: Number of contaminated units in group $j$ of consignment $i$, values $0,1,\ldots,m$  
- $Y_{ij}$: Presence of contamination in group $j$ of consignment $i$, $Y_{ij} = I(X_{ij}>0)$  
- $\widetilde{Y}_{ij}$: Observed test result for group $j$ of consignment $i$, accounting for measurement error  
- $T_{Xi}$: Total number of contaminated units in consignment $i$, $T_{Xi} = \sum_{j=1}^{B} X_{ij}$  
- $t_{xi}$: Number of contaminated units among sampled groups, $t_{xi} = \sum_{j=1}^{b} X_{ij}$  
- $t_{yi}$: Number of positive groups among sampled groups, $t_{yi} = \sum_{j=1}^{b} Y_{ij}$  
- $\tilde{t}_{yi}$: Number of positive tests among sampled groups, $\tilde{t}_{yi} = \sum_{j=1}^{b} \widetilde{Y}_{ij}$  
- $L_i$: Leakage in consignment $i$, defined as $L_i = T_{Xi} \, I(\tilde{t}_{yi}=0)$  
- $k$: Minimum biologically plausible positive prevalence  

## Nested Beta-binomial models

Now let $p_i$ denote the true prevalence of contamination in batch $i$, and define $\phi_{i} = 1 - (1 - p_i)^m$ as the probability that a group of $m$  items is contaminated. Assuming items are randomly distributed among bags, we have:

\[
X_{ij} \mid p_i \overset{\text{i.i.d.}}{\sim} \text{Bin}(m, p_i), \quad p_i \overset{\text{i.i.d.}}{\sim} \text{Beta}(\alpha, \beta).
\]

The group-level test outcome $\tilde{Y}_{ij}$ follows:

\[
\tilde{Y}_{ij} \mid p_i \sim \text{Bernoulli}(\tilde{\phi}_i), 
\]

and the observed number of positive groups in the sample follows:

\[
\tilde{t}_{yi} \mid p_i \sim \text{Binomial}(b, \tilde{\phi}_i).
\]

where the effective probability of a positive test is: 

\[
\tilde{\phi}_i = \Delta \phi_i + (1 - \Lambda)(1 - \phi_i) ; \quad \phi_i = 1 - (1 - p_i)^m.
\]


Under perfect specificity ($\Lambda = 1$), this simplifies to:

\[
\tilde{\phi}_i = \Delta \phi_i.
\]

When $\beta \gg \alpha$, the contamination prevalence $\beta p_i$ is approximately Gamma distributed, leading to:

\[
\tilde{\phi}_i \sim (1 - \Lambda) + \text{Beta} \left( \alpha, \frac{\beta}{m(\Delta + \Lambda - 1)} \right).
\]

Then two important special cases can be considered as:

* **Perfect testing** ($\Delta = 1$, $\Lambda = 1$): $\tilde{\phi}_i \sim \text{Beta}(\alpha, \beta / m)$,
* **Perfect specificity** ($\Lambda = 1$): $\tilde{\phi}_i \sim \text{Beta}(\alpha, \frac{\beta}{m \Delta})$.

In either case, $\tilde{t}_{yi}$ approximately follows a Beta-Binomial distribution when the infection is rare:

\[
\tilde{t}_{yi} \sim \textbf{Beta-Binomial}\ \Bigg(b, \alpha, \frac{\beta}{m \Delta}\Bigg).
\]

When a regulatory threshold ($k$) is defined such that contamination levels below a certain prevalence cut-off are considered unlikely, the effective prevalence can then be expressed as:

\[
p_i^{*} = p_i \cdot \mathbb{I}(p_i > k), \quad p_i \sim \text{Beta}(\alpha, \beta).
\]

Consideration of the new prevalence in the above-mentioned **BB model** leads to **truncated BB model**. Using the truncated model, the **probability of leakage** can be expressed as:

\[
\Pr[L_i > 0] = \frac{B_{(k_1,1)}(\alpha, \frac{\beta}{m\Delta} + b)}{B(\alpha, \frac{\beta}{m\Delta})} - \frac{B_{(k,1)}(\alpha, \beta + MB)}{B(\alpha, \beta)},
\]

with $k_1 = \Delta(1 - (1 - k)^m)$. Under perfect testing:

\[
\Pr[L_i > 0] = \frac{B_{(k,1)}(\alpha, \beta + mb)}{B(\alpha, \beta)} - \frac{B_{(k,1)}(\alpha, \beta + MB)}{B(\alpha, \beta)}.
\]

The **expected leakage** under threshold $k$ is:

\[
\mathbb{E}(L_i) = (B - b) M \cdot \mathbb{E}\left[ (1 - p_i)^{bm\Delta} \cdot p_i \cdot \mathbb{I}(p_i > k) \right],
\]

which simplifies to:

\[
\mathbb{E}(L_i) = (B - b) M \cdot \frac{B_{(k,1)}(\alpha + 1, \beta + bm\Delta)}{B(\alpha, \beta)}.
\]

When $k = 0$, these derivations reflect cases for the standard beta-binomial case.


## Functions Overview

The **`groupedBBMH`** package provides a set of functions for fitting, simulating, and evaluating grouped beta-binomial models for group-testing data. Key functions include:

- `loglik_group_bb`: Log-likelihood for grouped BB model with test error  
- `loglik_group_trbb`: Log-likelihood for truncated (minimum positive prevalence) grouped BB model with test error
- `fit_GroupedBB`: Fit grouped BB model using MLE  
- `fit_trGroupedBB`: Fit truncated grouped BB model using MLE
- `MH_Sampler_BB`: Metropolis-Hastings sampler for fitting grouped (truncated) BB models with test errors  
- `summary_mcmc`: Summarize MCMC outcomes with diagnostics  
- `create_mcmc_BP`: Create MCMC array for visualization using `bayesplot` R package  
- `DunnSmythTestBB`: Dunn-Smyth residual diagnostics for BB models  
- `estimate_leakage`: Estimate expected leakage and probability of leakage  
- `post_pred_sn`: Posterior predictive simulation for grouped BB model with imperfect sensitivity  
- `ppc_barplot`: Posterior predictive check (PPC) through creating barplots for observed and simulated counts and proportions  
- `post_pred_aprox_model`: Posterior predictive simulation for grouped BB models under perfect testing
- `simulate_infection_sampling`: Simulate infection sampling with (truncated) grouped BB models accounting sensitivity and minimum prevalence adjustments  
- `run_infection_simulations`: Run the simulation of infection sampling using  `simulate_infection_sampling` function 
- `compute_simulated_leakage`: Compute expected leakage and probability of leakage from model-based simulation output  

These functions allow users to fit exact models by incorporating minimum prevalence thresholds, test imperfections, and perform simulation-based evaluation and visualization of group-testing data.

## Correspondence to Equations in Das et al. (2025) paper

The following equations from the Barnes et al. (2025) form the statistical foundation of the `groupedHG` package:

- **Equation (1) & (2):** Two-level BB model for $X_{ij}$ 
- **Equation (3), (4) & (5):** Two-level BB model for $\tilde{t}_{yi}$ under imperfect testing
- **Equation (6):** PMF of $\tilde{t}_{yi}$ under imperfect testing  
- **Equation (12):** Approximate distribution $\tilde{t}_{yi}$  under imperfect testing  
- **Equation (12):** Approximate distribution $\tilde{t}_{yi}$  under imperfect sensitivity  
- **Equation (16):** Exact distribution $\tilde{t}_{yi}$  under imperfect testing
- **Equation (17):** Exact $\Pr[L_i>0]$ under perfect testing
- **Equation (18):** Exact $E(L_i)$ under perfect testing
- **Equation (19):** Approximate $\Pr[L_i>0]$ under imperfect sensitivity
- **Equation (20):** Approximate $E(L_i)$ under imperfect sensitivity





# Case Study: Frozen Seafood Importation in Australia

A real Australian biosecurity data extracted from Frozen Seafood Importation motivate our modeling approach. Each year, approximately 800 consignments (batches) of frozen seafood are imported into Australia. Each batch contains roughly $B = 8000$ bags, with each bag holding $M = 40$ items, yielding a total of $N = MB$ items per batch.

A simple random sample of $b = 13$ bags is selected from each batch for testing. From each selected bag, a group of $m = 5$ items (out of $M = 40$) is randomly chosen, resulting in $n = bm = 65$ sampled items per batch. Each group of $m$ items is tested using a PCR assay, which is assumed to have a sensitivity of approximately $\Delta = 0.80$ and near-perfect specificity, $\Lambda = 1.0$.

The only observation recorded per batch is the number of groups testing positive, out of the $b = 13$ groups tested.

These data motivate the development of models for estimating contamination prevalence, quantifying the risk of undetected contamination (leakage), and evaluating testing strategies under imperfect diagnostic accuracy.

The data used in this package for illustration and reproducibility are publicly available at 
[**Zenodo**](https://zenodo.org/records/7762164). 

For illustration, the frequency distribution of the number of positive test outcomes per batch, 
$\tilde{t}_{yi}$, is summarized as 
$t_y = (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13)$ and 
$f_y = (2815, 9, 10, 6, 1, 3, 2, 0, 1, 2, 1, 0, 0, 0)$. 

The distribution shows that approximately 99\% of the batches yielded no positive test results. 
However, when a batch tested positive, additional positive outcomes within the same batch 
were more likely to occur.
This pattern highlights the sparsity of the data and suggests that, once present, 
the infection tends to occur at or above a biologically meaningful minimum prevalence level, 
rather than at very low non-zero values.

# Basic Usage of R functions

This vignette illustrates how to perform maximum likelihood estimation (MLE) and MH algorithm for estimating parameters of a grouped Beta-Binomial model. The illustrations are conducted using the frozen seafood data.  



## Fitting BB model using MLE

For the given data, we first want to estimate parameters of a grouped Beta-Binomial (BB) model under a perfect testing scenario. This is done by maximizing the log-likelihood function that accounts for the grouped structure of the data. The likelihood function, implemented in the `loglik_group_bb()` function, can incorporate diagnostic test sensitivity and specificity. The maximization is carried out through the `optim()` function in R.

The function can be flexibly parameterized to estimate the shape parameters of the Beta distribution, $\alpha$ and $\beta$, given known sensitivity and specificity, or to estimate one parameter (such as $\alpha$) when another (such as $\mu$) is known. In more general settings, it can be extended to jointly estimate both Beta distribution parameters along with test inaccuracy parameters, depending on the available data and assumptions.

In the first example, we estimate the parameters of the grouped BB model assuming a perfect test (i.e., sensitivity and specificity both equal to 1). The optimization relies on numerical integration using $R = 10^4$ random draws from the Beta distribution. The optimization is performed on the log-scale to ensure positivity of parameters, and the resulting estimates for $\alpha$ and $\beta$ are obtained by exponentiating the optimized parameter values.


```{r chunk 1, eval=TRUE, echo=TRUE}
ty=c(0:13)
freq=c(2815, 9, 10, 6, 1, 3, 2, 0, 1, 2, 1, 0, 0, 0)
MLE.BB.m1 <- optim(c(0,0), loglik_group_bb, ty=ty, freq=freq, b=13,
                theta=Inf, m=5, M=40, deviance=FALSE,
                control=list(reltol=1e-12, fnscale=-1),
                R=1e4, hessian=FALSE, sensitivity=1, specificity=1)
MLE.BB.m1$mu <- exp(MLE.BB.m1$par[1]) / sum(exp(MLE.BB.m1$par))
MLE.BB.m1$alpha <- exp(MLE.BB.m1$par[1])
MLE.BB.m1$beta <- exp(MLE.BB.m1$par[2])
MLE.BB.m1
```

In the second example, we examine whether all the beta parameters and test parameters can be estimate by maximzing the log-likelihood function. The optimization requires specification of lower and upper values for the targeted parameters. The optimization shows that maximum value of log-likelood value is obtained for $\Delta=0.74$ and $\Lambda=1$, when $\alpha=0.0045$ and $\beta=3.78$.

In the second example, we fit the model to estimate all parameters simultaneously — that is, both Beta distribution parameters ($\alpha$ and $\beta$) and test inaccuracy parameters ($\Delta$ and $\Lambda$). This general case allows us to evaluate how test imperfections affect the estimated prevalence distribution.

To ensure stable optimization, lower and upper bounds are specified for all parameters. The optimization process searches the parameter space within these limits to find the combination that maximizes the log-likelihood function. The results demonstrate that the maximum log-likelihood occurs when $\Delta = 0.74$ and $\Lambda = 1$, corresponding to $\alpha = 0.0045$ and $\beta = 3.78$. These results indicate moderate overdispersion in the underlying Beta-Binomial model and the test has imperfect sensitivity but near-perfect specificity.

```{r chunk 2, eval=TRUE, echo=TRUE}
MLE.BB.m6 <- optim(
  c(0,0,0,0), loglik_group_bb,
  ty = ty, freq = freq, b = 13,
  theta = Inf, m = 5, M = 40,
  deviance = FALSE,
  control = list(factr = 1e-12, fnscale = -1, trace = TRUE),
  R = 1e4, hessian = FALSE,
  method = "L-BFGS-B",
  lower = c(log(0.0001), log(0.0001), log(0.5), log(0.99)),
  upper = c(Inf, Inf, 0, 0)
)

MLE.BB.m6$mu <- exp(MLE.BB.m6$par[1]) / sum(exp(MLE.BB.m6$par))
MLE.BB.m6$alpha <- exp(MLE.BB.m6$par[1])
MLE.BB.m6$beta  <- exp(MLE.BB.m6$par[2])
MLE.BB.m6$sensitivity  <- exp(MLE.BB.m6$par[3])
MLE.BB.m6$specificity  <- exp(MLE.BB.m6$par[4])
MLE.BB.m6
```

Overall, these two examples illustrate how the grouped Beta-Binomial likelihood framework, implemented through the `loglik_group_bb()` function, can flexibly accommodate a range of scenarios — from perfect testing conditions to fully parameterized cases that account for test inaccuracy. This approach provides a robust foundation for modeling overdispersed group testing data in the presence of measurement error.

As a user-friendly alternative to manual optimization, the `fit_GroupedBB()` function offers a convenient interface for fitting the grouped Beta-Binomial model. For a given set of sensitivity and specificity values, it estimates the Beta-Binomial parameters by maximizing the likelihood function. The function returns the estimated Beta distribution parameters and, when `leakage = TRUE` is specified, also provides estimates of leakage parameters - expected leakage and probability of leakage per batch. It is noted that for leakage estimation, the number of groups per batch $B$ and the actual group size in the cases study ($M$) is required.  


```{r chunk 3, eval=TRUE, echo=TRUE}
bb.m1 <- fit_GroupedBB(ty = ty, freq = freq, b = 13, m = 5,
                       sensitivity = 1, specificity = 1)
bb.m1
```

```{r chunk 4, eval=TRUE, echo=TRUE}
# Fit model with leakage (requires B and M)
bb.m2 <- fit_GroupedBB(ty = ty, freq = freq, b = 13, m = 5, M = 40, B = 8000,
                       sensitivity = 1, specificity = 1, leakage = TRUE)
bb.m2
```

When a biologically meaningful threshold is introduced for the batch-level infection prevalence ($p_i$), the model must account for the fact that values below this threshold are biologically implausible. The `groupedBBMH` package accommodates this feature through the truncated beta-binomial model, where the log-likelihood is maximized using the function `loglik_group_trbb()`.

To simplify implementation, the high-level function `fit_trGroupedBB()` provides a user-friendly interface for estimating the beta distribution parameters while incorporating a specified threshold value $k$.

In the first example below, we fit the truncated beta-binomial model with a threshold of $k=0$ (i.e., no truncation) under perfect test conditions using `fit_trGroupedBB()` with $R = 10^4$ for numerical integration. The results are comparable to those obtained using the standard `fit_GroupedBB()` function.

In the second example, we demonstrate a model fit with a 1% minimum prevalence threshold ($k=0.01$) under imperfect test conditions, where sensitivity ($\Delta = 0.8$) and specificity ($\Lambda = 1$). This allows us to evaluate how the model responds when small non-zero prevalence values are restricted by biological constraints.



```{r chunk 5, eval=TRUE, echo=TRUE}
# Fit truncated grouped beta-binomial model with cutoff = 0 (no truncation) with perfect test
trbb.m1 <- fit_trGroupedBB(ty, freq, b = 13, m = 5, cutoff = 0,R=10^4)
trbb.m1
```


```{r chunk 6, eval=TRUE, echo=TRUE}
# Fit truncated grouped beta-binomial model with cutoff = 0.01 and imperfect sensitivity
trbb.m2 <- fit_trGroupedBB(ty, freq, b = 13, m = 5, cutoff = 0.01,
                       sensitivity = 0.8, specificity = 1)
trbb.m2
```


## Fitting BB model using MH 

Now, we fit the grouped beta-binomial (BB) model using the Metropolis–Hastings (MH) algorithm. The `MH_Sampler_BB()` function implements the MH sampling procedure for specified values of test sensitivity and specificity. Following the setup described in the paper, two prior specifications were considered for the test sensitivity: one with fixed $\Delta = 0.8$, and another where $\Delta$ was uniformly distributed between 0.75 and 0.85.

The MH algorithm is constructed based on the frequency distribution of $\tilde{t}_{yi}$, allowing the weighted log-likelihood of the beta-binomial model to be computed exactly through numerical integration. The priors for the model parameters (e.g., $\alpha$ and $\mu$) were chosen to ensure that parameter estimates remain within expected, interpretable ranges.

The MH algorithm was run on the parameter set $\theta_1$, $\theta_2$, and, when $\Delta$ was not fixed, $\theta_3$. Specifically, we defined $\theta_1 = \log(\alpha)$ with prior $\theta_1 \sim U(-A, A)$, and $\mu = \text{expit}(\theta_2)$. When $\Delta$ was not fixed, it was parameterized as $\Delta = 0.75 + 0.1 \times \text{expit}(\theta_3)$. These definitions yield induced priors of $\mu \sim U(0,1)$ and $\Delta \sim U(0.75, 0.85)$.

For proposal distributions, each parameter ($\theta_1$, $\theta_2$, $\theta_3$) was updated as the previous value plus a normal perturbation with mean zero. A proposal standard deviation of $\sigma = 0.2$ provided satisfactory convergence, with low autocorrelation and stable parameter estimates. The model was fitted using $5 \times 10^4$ iterations, with the first half discarded as burn-in. From the remaining samples, every fifth draw (`thin = 5`) was retained to reduce autocorrelation in the MCMC chains.

Convergence was evaluated using trace plots and posterior density plots. For demonstration purposes, an example model was also fitted using a smaller number of iterations ($R = 1000$) to illustrate the structure of the MCMC output. Here, $R$ denotes the number of MCMC iterations, while $G$ represents the number of quantiles used in the numerical integration.

We fit the first model using the R code shown below for the fixed sensitivity $\Delta = 0.8$ and examined the summary statistics of the target parameters of the beta distribution. These summaries provide insight into the posterior location and variability of the parameters, helping to assess the model’s fit and stability. Additionally, the estimated posterior means and credible intervals can be compared with the maximum likelihood estimates obtained earlier to evaluate the consistency and robustness of the inference.

```{r chunk 7, eval=TRUE, echo=TRUE}
MH.trbb.m1 <- MH_Sampler_BB(par = c(log(0.005), logit(7e-04), logit(0.75)),
  cutoff = 0.01,
  alpha = TRUE, beta = FALSE, mu = TRUE, rho = FALSE,
  G = 500, R = 1000,
  sigma = c(0.20, 0.20, 0.20),
  num_chains = 3,
  burnin = 500, thin = 2,
  seed = c(123, 456, 789, 102),
  trail = 13,
  ty = ty,
  wt = freq,
  group.size = 5,
  sensitivity = TRUE,
  specificity = FALSE,
  sensitivity.range=c(0.80,0.80),
  specificity.range=NULL)
```

Summary statistics of the target parameters, obtained using the `summary_mcmc()` function, provide a comprehensive overview of the posterior distributions, including measures such as the mean, standard deviation, and credible intervals. In addition, the function reports key MCMC diagnostics — such as effective sample size and potential scale reduction factor (R-hat) — which help assess convergence and sampling efficiency. Together, these outputs offer valuable insights into the stability and reliability of the parameter estimates derived from the Metropolis–Hastings algorithm.

```{r chunk 8, eval=TRUE, echo=TRUE}
summ.MH.m1 <- summary_mcmc(MH.trbb.m1$target.parameters$alpha_sample,
                           MH.trbb.m1$target.parameters$beta_sample,
                           MH.trbb.m1$target.parameters$mu_sample,
                           varnames = c("alpha", "beta", "mu"))
(summ.MH.m1$summary_mcmc)
```
We now fit the second MH-based BB model using the R code below, assuming the sensitivity parameter follows a uniform distribution on $(0.75, 0.85)$. In this setup, we set a proposal standard deviation of $\sigma = 2$ for the sensitivity parameter, while retaining $\sigma = 0.2$ for the $\alpha$ and $\mu$ parameters.

```{r chunk 9, eval=TRUE, echo=TRUE}
MH.trbb.m2 <- MH_Sampler_BB(par = c(log(0.005), logit(7e-04), logit(0.75)),
  cutoff = 0.01,
  alpha = TRUE, beta = FALSE, mu = TRUE, rho = FALSE,
  G = 500, R = 1000,
  sigma = c(0.20, 0.20, 2),
  num_chains = 3,
  burnin = 500, thin = 2,
  seed = c(123, 456, 789, 102),
  trail = 13,
  ty = ty,
  wt = freq,
  group.size = 5,
  sensitivity = TRUE,
  specificity = FALSE,
  sensitivity.range=c(0.75,0.85),
  specificity.range=NULL)
```

The `summary_mcmc` function provides summary statistics for the MCMC simulations of all targeted parameters, including $\alpha$, $\mu$, and $\Delta$.

```{r chunk 10, eval=TRUE, echo=TRUE}
summ.MH.m2 <- summary_mcmc(MH.trbb.m2$target.parameters$alpha_sample,
                           MH.trbb.m2$target.parameters$beta_sample,
                           MH.trbb.m2$target.parameters$sensitivity_sample,
                           varnames = c("alpha", "beta", "sensitivity"))
(summ.MH.m2$summary_mcmc)
```

MCMC diagnostics can be conveniently performed using the `bayesplot` R package, which provides a rich set of visualization tools for assessing convergence, autocorrelation, and distribution of MCMC samples. To use `bayesplot`, the MCMC simulations must first be converted into a format compatible with the package. The `create_mcmc_BP()` function in `groupedBBMH` facilitates this conversion by transforming the MCMC output into a three-dimensional array of shape (iterations × chains × parameters). Once the array is prepared, `bayesplot` functions can be applied to visualize the posterior distributions, trace plots, and other diagnostics for the transformed parameters across different chains. The R code below illustrates how to convert the MCMC output and generate diagnostic plots to assess convergence and parameter behavior across chains.

```{r chunk 11, eval=TRUE, echo=TRUE}
MCMC.MH.m2 <- lapply(MH.trbb.m2$parameters, function(mat) mat[, 1:3])
var.names <- c("log(alpha)","logit(mu)","logit(sensitivity)")
MCMC.MH.m2 <- create_mcmc_BP(MCMC.MH.m2,var.names)
color_scheme_set("viridis")
p1_mcmc_trace <- bayesplot::mcmc_trace(MCMC.MH.m2)  # Density overlay for known sensitivity
p2_dens_overlay <- bayesplot::mcmc_dens_overlay(MCMC.MH.m2) # Density overlay for unknown sensitivity
ggarrange(p1_mcmc_trace,p2_dens_overlay,nrow = 2)
```

The trace plots and overlay density plots provide visual diagnostics of MCMC convergence, allowing us to assess whether the chains have mixed well and stabilized around the posterior distributions for the considered parameters under `varnames`.


## Model Checking 

For illustration, we evaluated the MH-fitted BB model with fixed sensitivity $\Delta=0.8$ using Dunn-Smyth randomized quantile residuals (Dunn and Smyth, 1996) and posterior predictive checks against the observed frequency data. Although similar diagnostics could be applied to ML- or HMC-fitted models, or for positive thresholds $k$, we focus here on the MH fit with $k=0$ for simplicity. Posterior uncertainty is incorporated in the Dunn-Smyth residuals through the empirical cumulative distribution of simulated counts, and the residuals are subsequently transformed to a standard normal scale for Q-Q plot evaluation. Further details are provided in Das et al. (2025).

```{r chunk 12, eval=TRUE, echo=TRUE}
# Expand frequency table into a vector of observed responses
ObservedResponse <- rep(ty, times = freq)

# Run Dunn-Smyth residual diagnostic using posterior samples
set.seed(123456)
DSTest_MH_Imperfect <- DunnSmythTestBB_Custom(
  ObservedResponse = ObservedResponse,
  size = 13,
  group_size = 5,
  approximate.model = FALSE,
  alpha = unlist(MH.trbb.m1$target.parameters$alpha_sample),
  beta  = unlist(MH.trbb.m1$target.parameters$beta_sample)
)

# Display diagnostic plots
DSTest_MH_Imperfect$DS_hist       # Histogram of Dunn-Smyth residuals
DSTest_MH_Imperfect$DS_QQ_norm    # Normal Q-Q plot of scaled residuals

# Print KS test result for Uniformity
DSTest_MH_Imperfect$KS

```

For doing Posterior predictive check of the fitted model, we use the posterior distribution of $\alpha$ and $\beta$ obatined from the fitted model `MH.trbb.m1` considering $k=0.01$ and $\Delta=0.8$. The comparison of counts and their proportions from the observed outcomes are compared with simulated counts. In the below two bar-plots, the shaded areas represent the observed counts (proportions), while the error bars indicate the 95\% credible interval of simulated counts (proportions). For the plot of counts, the left y-axis is scaled from 0 to 3000 for zero value of $\tilde{t}_{yi}$, while the right y-axis is scaled from 0 to 30 for non-zero values of $\tilde{t}_{yi}$.


```{r chunk 13, eval=TRUE, echo=TRUE,warning=FALSE,message=FALSE}

# Observed outcomes from D batches
ObservedResponse <- rep(ty, times = freq)

# Generate posterior predictive draws using the 'post_pred_sn' function
predicted.counts.imperfect.case <- post_pred_sn(
  D = length(ObservedResponse),   # Number of batches (observed outcomes)
  n = 13,                 # Number of group tests per batch
  m = 5,                  # Pool size in group test
  alpha = unlist(MH.trbb.m1$target.parameters$alpha_sample),
  beta = unlist(MH.trbb.m1$target.parameters$beta_sample),
  sensitivity = 0.8
)

# Check proportions of observed vs simulated counts (for model diagnostics)
prop.table(table(ObservedResponse))                      # Observed data distribution
prop.table(table(predicted.counts.imperfect.case$ty_rep))   # Simulated data distribution

# ----------------------------------------------------------------------------------#
# Posterior Predictive Check Visualization
# ----------------------------------------------------------------------------------#

# Generate barplots comparing observed and replicated counts
ppc.barplot.imperfect.case <- ppc_barplot(
  ty = ObservedResponse,
  yrep = predicted.counts.imperfect.case$ty_rep,
  trial = 13
)
ppc.barplot.imperfect.case$p.zero.non.zero     # Combined plot
ppc.barplot.imperfect.case$prop.zero.non.zero  # Zero vs non-zero proportion values

```


## Model-based Community Risk assessment 



# Session Info & References

```{r Session}
sessionInfo()
```

# References

- Barnes, B., Parsa, M., Das, S., & Clark, R. (2025). *Hypergeometric and Binomial Group Sampling with Sensitivity and Specificity*. Submitted to *Communications in Statistics -- Theory and Methods*.
- Arnold, M. E., Cook, A., & Davies, R. (2005). A modelling approach to estimate the sensitivity of pooled faecal samples for isolation of Salmonella in pigs. *Journal of the Royal Society Interface*, 2(4), 365–372.
- Theobald, C. M., & Davie, A. M. (2014). Group testing, the pooled hypergeometric distribution, and estimating the number of defectives in small populations. *Communications in Statistics -- Theory and Methods*, 43(14), 3019–3026.
